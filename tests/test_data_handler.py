# pylint: disable=line-too-long, missing-docstring, unspecified-encoding
"""
Tests for the DataHandler class using synthetic data generated by Faker.
Environment variables:
    CALCULATOR_HISTORY_FOLDER_PATH = 'data'
    CALCULATOR_HISTORY_FILE_NAME = 'calculator_history.csv'
"""

from decimal import Decimal
import os
import logging
from types import SimpleNamespace
import pandas as pd

import pytest

from data_handler import DataHandler
from calculator.calculation import Calculation
from calculator.statistic import CalculationStatistic


def dummy_op(num1, num2):
    """A dummy operation that returns the sum of the given numbers."""
    return num1 + num2
dummy_op.__name__ = "dummy_op"


@pytest.fixture
def data_handler_tmp(tmp_path, monkeypatch):
    """
    Fixture that sets up environment variables and a temporary folder/file for DataHandler.
    The environment variables are set to:
      CALCULATOR_HISTORY_FOLDER_PATH = 'data'
      CALCULATOR_HISTORY_FILE_NAME = 'calculator_history.csv'
    """
    folder = tmp_path / "data"
    folder.mkdir()
    monkeypatch.setenv("CALCULATOR_HISTORY_FOLDER_PATH", str(folder))
    monkeypatch.setenv("CALCULATOR_HISTORY_FILE_NAME", "calculator_history.csv")
    return DataHandler()


def test_init_missing_env(monkeypatch):
    """Test that __init__ raises ValueError when required environment variables are missing."""
    monkeypatch.setenv("CALCULATOR_HISTORY_FOLDER_PATH", "")
    monkeypatch.setenv("CALCULATOR_HISTORY_FILE_NAME", "")
    with pytest.raises(ValueError):
        DataHandler()


def test_load_csv_data_file_not_found(data_handler_tmp, caplog):
    """Test that load_csv_data() returns an empty list when the CSV file does not exist."""
    if os.path.exists(data_handler_tmp.csv_filepath):
        os.remove(data_handler_tmp.csv_filepath)
    data = data_handler_tmp.load_csv_data()
    assert data == []
    assert "CSV file not found" in caplog.text


def test_load_csv_data_success(data_handler_tmp, faker):
    """Test that load_csv_data() successfully reads CSV data when the file exists."""
    a_val = faker.pydecimal(left_digits=2, right_digits=2, positive=True)
    b_val = faker.pydecimal(left_digits=1, right_digits=2, positive=True)
    operator = "add"
    df = pd.DataFrame([{"num_1": str(a_val), "num_2": str(b_val), "operator": operator}])
    df.to_csv(data_handler_tmp.csv_filepath, index=False)
    data = data_handler_tmp.load_csv_data()
    assert len(data) == 1
    assert float(data[0]["num_1"]) == float(a_val)
    assert float(data[0]["num_2"]) == float(b_val)
    assert data[0]["operator"] == operator


def test_load_csv_data_exception(data_handler_tmp, monkeypatch, caplog):
    """Test that load_csv_data() handles exceptions when reading the CSV file."""
    monkeypatch.setattr(pd, "read_csv", lambda filepath: (_ for _ in ()).throw(RuntimeError("Read error")))
    # Write a dummy file so that os.path.exists returns True.
    with open(data_handler_tmp.csv_filepath, "w") as f:
        f.write("dummy")
    data = data_handler_tmp.load_csv_data()
    assert data == []
    assert "Error reading CSV file: Read error" in caplog.text


def test_add_to_csv(data_handler_tmp, faker):
    """
    Test that add_to_csv() correctly appends a calculation record for both normal and statistic operations.
    """
    data_handler_tmp.clear_csv_data()

    # Normal calculation: generate synthetic numbers.
    normal_calc = SimpleNamespace()
    normal_calc.a = float(faker.pydecimal(left_digits=2, right_digits=2, positive=True))
    normal_calc.b = float(faker.pydecimal(left_digits=2, right_digits=2, positive=True))
    normal_calc.operation = dummy_op

    data_handler_tmp.add_to_csv(normal_calc)
    data = data_handler_tmp.get_csv_data()
    assert len(data) == 1
    assert data[0] == {
        "num_1": normal_calc.a,
        "num_2": normal_calc.b,
        "operator": "dummy_op",
    }

    # Statistic calculation: generate a synthetic list of Decimals.
    stat_calc = SimpleNamespace()
    stat_calc.a = [
        Decimal(str(faker.pydecimal(left_digits=1, right_digits=2, positive=True)))
        for _ in range(3)
    ]
    stat_calc.b = 0
    stat_calc.operation = dummy_op
    data_handler_tmp.add_to_csv(stat_calc)
    data = data_handler_tmp.get_csv_data()
    assert len(data) == 2
    assert data[1]["num_1"] == repr(stat_calc.a)
    assert data[1]["num_2"] == 0
    assert data[1]["operator"] == "dummy_op"


def test_save_csv_data(data_handler_tmp, monkeypatch, caplog, faker):
    """
    Test that save_csv_data() writes CSV data to the file and logs errors on failure.
    """
    a_val = faker.pydecimal(left_digits=2, right_digits=2, positive=True)
    b_val = faker.pydecimal(left_digits=2, right_digits=2, positive=True)
    data_handler_tmp.csv_data = [{"num_1": str(a_val), "num_2": str(b_val), "operator": "add"}]
    file_path = data_handler_tmp.csv_filepath
    if os.path.exists(file_path):
        os.remove(file_path)
    data_handler_tmp.save_csv_data()
    df = pd.read_csv(file_path)
    assert len(df) == 1
    assert float(df.loc[0, "num_1"]) == float(a_val)
    assert float(df.loc[0, "num_2"]) == float(b_val)
    assert df.loc[0, "operator"] == "add"

    # Simulate an error during saving.
    def dummy_to_csv(*args, **kwargs):
        raise RuntimeError("Simulated error")
    monkeypatch.setattr(pd.DataFrame, "to_csv", dummy_to_csv)
    with caplog.at_level(logging.ERROR):
        data_handler_tmp.save_csv_data()
    assert "Error saving data to CSV: Simulated error" in caplog.text


def test_clear_csv_data(data_handler_tmp, caplog):
    """Test that clear_csv_data() empties the in-memory CSV data."""
    data_handler_tmp.csv_data = [{"dummy": "data"}]
    data_handler_tmp.clear_csv_data()
    assert data_handler_tmp.get_csv_data() == []
    assert "CSV data cleared." in caplog.text


def test_get_csv_data(data_handler_tmp, faker):
    """Test that get_csv_data() returns the current CSV data."""
    sample = [{"a": faker.word()}]
    data_handler_tmp.csv_data = sample
    data = data_handler_tmp.get_csv_data()
    assert data == sample


def test_convert_to_calculation_statistic_valid(data_handler_tmp, caplog, faker):
    """
    Test that convert_to_calculation() converts a statistic row with valid eval to a CalculationStatistic.
    """
    stat_values = [
        Decimal(str(faker.pydecimal(left_digits=1, right_digits=2, positive=True)))
        for _ in range(3)
    ]
    row = {"num_1": repr(stat_values), "num_2": None, "operator": "mean"}
    data_handler_tmp.csv_data = [row]
    calculations = data_handler_tmp.convert_to_calculation()
    assert len(calculations) == 1
    assert isinstance(calculations[0], CalculationStatistic)
    assert calculations[0].a == stat_values


def test_convert_to_calculation_statistic_invalid(data_handler_tmp, caplog):
    """
    Test that convert_to_calculation() handles a statistic row with invalid eval.
    """
    row = {"num_1": "not_a_list", "num_2": None, "operator": "median"}
    data_handler_tmp.csv_data = [row]
    calculations = data_handler_tmp.convert_to_calculation()
    assert len(calculations) == 1
    assert isinstance(calculations[0], CalculationStatistic)
    assert calculations[0].a == "not_a_list"
    assert "Error converting num_1 to list of Decimals:" in caplog.text


def test_convert_to_calculation_normal_valid(data_handler_tmp, faker):
    """
    Test that convert_to_calculation() converts a normal calculation row with valid float strings.
    """
    a_val = faker.pydecimal(left_digits=2, right_digits=2, positive=True)
    b_val = faker.pydecimal(left_digits=2, right_digits=2, positive=True)
    row = {"num_1": str(a_val), "num_2": str(b_val), "operator": "add"}
    data_handler_tmp.csv_data = [row]
    calculations = data_handler_tmp.convert_to_calculation()
    assert len(calculations) == 1
    assert isinstance(calculations[0], Calculation)
    # Values are converted to float.
    assert calculations[0].a == float(str(a_val))
    assert calculations[0].b == float(str(b_val))


def test_convert_to_calculation_normal_invalid(data_handler_tmp):
    """
    Test that convert_to_calculation() handles a normal calculation row with non-numeric values.
    """
    row = {"num_1": "non_numeric", "num_2": "also_non_numeric", "operator": "subtract"}
    data_handler_tmp.csv_data = [row]
    calculations = data_handler_tmp.convert_to_calculation()
    assert len(calculations) == 1
    assert isinstance(calculations[0], Calculation)
    # Since conversion to float fails, values should remain as original strings.
    assert calculations[0].a == "non_numeric"
    assert calculations[0].b == "also_non_numeric"


def test_delete_csv_file_data(data_handler_tmp, monkeypatch, caplog):
    """
    Test that delete_csv_file_data() clears the in-memory CSV data and calls save_csv_data().
    """
    data_handler_tmp.csv_data = [{"dummy": "data"}]
    called = False

    def fake_save():
        nonlocal called
        called = True

    monkeypatch.setattr(data_handler_tmp, "save_csv_data", fake_save)
    data_handler_tmp.delete_csv_file_data()
    assert data_handler_tmp.get_csv_data() == []
    assert called is True
    assert "CSV data cleared." in caplog.text
